# Hyperbolic Attention

This project aims to investigate the use of `tanh` as the basis for formulating `softmax` instead of the `logistic function (sigmoid)`.


## TODO:
- Finalize model code
    - make sure implementation can be trained (done)
    - decoder (need to implement into Transformer Class)
    - change config structure
- Create training code (done)
- Finalize dataset selection
    - C4 or TinyStories
- Finalize model hyper-params
- Run tests